{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd75d00d-7b68-45ee-b8a2-89aa88ce6607"
      },
      "source": [
        "# [모의 경진대회] 토지피복지도 객체 분할\n",
        "\n",
        "* Image Segmentation\n"
      ],
      "id": "bd75d00d-7b68-45ee-b8a2-89aa88ce6607"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "895492f7-0ddc-437b-939c-da0eabe42b6a"
      },
      "source": [
        "## 데이터 디렉토리 구조"
      ],
      "id": "895492f7-0ddc-437b-939c-da0eabe42b6a"
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA/\n",
        "#   \\_train/\n",
        "#        \\_traindf.csv  \n",
        "#        \\_images/\n",
        "#            \\_xxx.png\n",
        "#            \\_yyy.png\n",
        "#            \\_zzz.png\n",
        "#            \\_...  \n",
        "#        \\_masks/\n",
        "#            \\_xxx.png\n",
        "#            \\_yyy.png\n",
        "#            \\_zzz.png\n",
        "#            \\_...\n",
        "#   \\_test/\n",
        "#        \\_sample_submission.csv\n",
        "#        \\_testdf.csv\n",
        "#        \\_images/\n",
        "#            \\_aaa.png  \n",
        "#            \\_bbb.png  \n",
        "#            \\_...  "
      ],
      "metadata": {
        "id": "75b185d7-6875-48bd-bae9-279a23d7ddb4"
      },
      "id": "75b185d7-6875-48bd-bae9-279a23d7ddb4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B_-EdnEy-s1H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4962d8f9-4b29-467b-ab95-a6a487181cd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "B_-EdnEy-s1H"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNGKR0i4Fa43"
      },
      "outputs": [],
      "source": [
        "# !unzip '/content/drive/MyDrive/Colab Notebooks/YearDream-Kaggle/2nd/DATA/train.zip' -d '/content/drive/MyDrive/Colab Notebooks/YearDream-Kaggle/2nd/DATA/'"
      ],
      "id": "zNGKR0i4Fa43"
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip '/content/drive/MyDrive/Colab Notebooks/YearDream-Kaggle/2nd/DATA/test.zip' -d '/content/drive/MyDrive/Colab Notebooks/YearDream-Kaggle/2nd/DATA/'"
      ],
      "metadata": {
        "id": "mgXDahCPv1Sm"
      },
      "id": "mgXDahCPv1Sm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5f16bf1-a097-47b6-8a19-89155f7d6c09"
      },
      "source": [
        "## 필수 라이브러리 불러오기"
      ],
      "id": "a5f16bf1-a097-47b6-8a19-89155f7d6c09"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4NScJz6c-V5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1990a365-3716-4703-91ea-bfba5c2d866a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: segmentation_models_pytorch in /usr/local/lib/python3.8/dist-packages (0.3.1)\n",
            "Requirement already satisfied: efficientnet-pytorch==0.7.1 in /usr/local/lib/python3.8/dist-packages (from segmentation_models_pytorch) (0.7.1)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.8/dist-packages (from segmentation_models_pytorch) (0.13.1+cu113)\n",
            "Requirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.8/dist-packages (from segmentation_models_pytorch) (0.7.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from segmentation_models_pytorch) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from segmentation_models_pytorch) (4.64.1)\n",
            "Requirement already satisfied: timm==0.4.12 in /usr/local/lib/python3.8/dist-packages (from segmentation_models_pytorch) (0.4.12)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.12.1+cu113)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.8/dist-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation_models_pytorch) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install segmentation_models_pytorch"
      ],
      "id": "4NScJz6c-V5P"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "609f5ad9-9f65-4fa6-b987-8fcad156d417"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import segmentation_models_pytorch as smp\n",
        "from segmentation_models_pytorch.losses import DiceLoss\n",
        "\n",
        "import albumentations as A\n",
        "import cv2\n",
        "from datetime import datetime, timezone, timedelta"
      ],
      "id": "609f5ad9-9f65-4fa6-b987-8fcad156d417"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b1220bd-5501-400d-952e-8c185a3d004b"
      },
      "source": [
        "## 하이퍼파라미터 및 기타 인자 설정"
      ],
      "id": "3b1220bd-5501-400d-952e-8c185a3d004b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae2fab69-2736-4486-9754-14ebb2f20018"
      },
      "source": [
        "#### 데이터 경로"
      ],
      "id": "ae2fab69-2736-4486-9754-14ebb2f20018"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eaf86952-1acf-4b07-87e9-1ce6621e74c0"
      },
      "outputs": [],
      "source": [
        "# 프로젝트 경로\n",
        "PROJECT_DIR = '/content/drive/MyDrive/Colab Notebooks/YearDream-Kaggle/2nd'\n",
        "os.chdir(PROJECT_DIR)\n",
        "\n",
        "#데이터 경로\n",
        "DATA_DIR = os.path.join(PROJECT_DIR, 'DATA') # 모든 데이터가 들어있는 폴더 경로\n",
        "TRAIN_DIR = os.path.join(DATA_DIR, 'train') # 학습 데이터가 들어있는 폴더 경로\n",
        "TRAIN_IMG_DIR = os.path.join(TRAIN_DIR, 'images') # 학습 이미지가 들어있는 폴더 경로\n",
        "TRAIN_MASK_DIR = os.path.join(TRAIN_DIR, 'masks') # 학습 마스크가 들어있는 폴더 경로\n",
        "TRAIN_CSV_FILE = os.path.join(TRAIN_DIR, 'traindf.csv') # 학습 이미지와 마스크 이름이 들어있는 CSV 경로"
      ],
      "id": "eaf86952-1acf-4b07-87e9-1ce6621e74c0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 수량 확인:\n",
        "- n_train = 3930\n",
        "- n_test = 3930"
      ],
      "metadata": {
        "id": "EYMnx6-bmYtA"
      },
      "id": "EYMnx6-bmYtA"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IavNsHk9B0Zn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c866d8da-c1fe-41d1-f627-481ebf739de9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3930"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "len(os.listdir(TRAIN_IMG_DIR)) #3930"
      ],
      "id": "IavNsHk9B0Zn"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ETP02sKgB5F4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48aee88c-a68a-4fa1-8ae6-5e291ee4bbab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3930"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "len(os.listdir(TRAIN_MASK_DIR)) #3930"
      ],
      "id": "ETP02sKgB5F4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 결과 저장 경로 설정"
      ],
      "metadata": {
        "id": "5GwfSKc5W1K0"
      },
      "id": "5GwfSKc5W1K0"
    },
    {
      "cell_type": "code",
      "source": [
        "# 시간 고유값 \n",
        "kst = timezone(timedelta(hours=9))        \n",
        "train_serial = datetime.now(tz=kst).strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# 기록 경로\n",
        "RECORDER_DIR = os.path.join(PROJECT_DIR, 'results', 'train', train_serial)\n",
        "# 현재 시간 기준 폴더 생성\n",
        "os.makedirs(RECORDER_DIR, exist_ok=True)    "
      ],
      "metadata": {
        "id": "WHoqlnqxW02M"
      },
      "id": "WHoqlnqxW02M",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f2717f1-9c63-469b-8c24-ac63cc9c2e83"
      },
      "source": [
        "#### 시드 설정"
      ],
      "id": "1f2717f1-9c63-469b-8c24-ac63cc9c2e83"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "578e57e9-2e0c-4802-a7b3-79868119de61"
      },
      "outputs": [],
      "source": [
        "RANDOM_SEED = 2022 #랜덤 시드\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)"
      ],
      "id": "578e57e9-2e0c-4802-a7b3-79868119de61"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21b77e5e-de69-4387-881d-7a223804556a"
      },
      "source": [
        "#### 디바이스 설정"
      ],
      "id": "21b77e5e-de69-4387-881d-7a223804556a"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "41ee20b1-2097-47f5-85bc-010f1674cd5a"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "id": "41ee20b1-2097-47f5-85bc-010f1674cd5a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecaf0022-98af-4cfd-90e1-8221a31b6c74"
      },
      "source": [
        "#### 하이퍼파라미터 설정"
      ],
      "id": "ecaf0022-98af-4cfd-90e1-8221a31b6c74"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "c6b0a51c-9f25-4627-8d0e-6827aae6e448"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 20\n",
        "BATCH_SIZE = 4\n",
        "LEARNING_RATE = 0.001\n",
        "EARLY_STOPPING_PATIENCE = 10\n",
        "IMG_SIZE = 512\n",
        "\n",
        "ENCODER = 'timm-efficientnet-b4' # 활용할 인코더 모델\n",
        "WEIGHTS = 'noisy-student' # Pre-train에 활용된 데이터셋"
      ],
      "id": "c6b0a51c-9f25-4627-8d0e-6827aae6e448"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02c4ca8d-3015-4cb3-bdfe-7c8cd63a7782"
      },
      "source": [
        "## Dataset 정의"
      ],
      "id": "02c4ca8d-3015-4cb3-bdfe-7c8cd63a7782"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "70b2ad0e-6461-4a55-9557-6d0c5e49678c"
      },
      "outputs": [],
      "source": [
        "class SegDataset(Dataset):\n",
        "    def __init__(self, df, augmentations, img_dir, mask_dir):\n",
        "        self.df = df # 이미지와 마스크 이름이 저장된 데이터프레임 \n",
        "        self.augmentations = augmentations # 학습 전 적용할 augmentation\n",
        "        self.img_dir = img_dir # 이미지 폴더 경로\n",
        "        self.mask_dir = mask_dir # 마스크 폴더 경로\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # 데이터 프레임 불러와서 이미지와 마스크 경로 설정\n",
        "        row = self.df.iloc[idx] # 데이터프레임 행 불러오기\n",
        "        image_path = os.path.join(self.img_dir,row['img'])\n",
        "        mask_path = os.path.join(self.mask_dir, row['mask'])\n",
        "        \n",
        "        # 이미지와 마스크 불러오기\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        mask = np.expand_dims(mask, axis=-1)\n",
        "        \n",
        "        # Augmentation 적용하기\n",
        "        if self.augmentations:\n",
        "            data = self.augmentations(image=image, mask=mask)\n",
        "            image = data['image']\n",
        "            mask = data['mask']\n",
        "        \n",
        "        # PyTorch 인풋 모양에 맞게 이미지와 마스크 모양 변경\n",
        "        image = np.transpose(image, (2,0,1)).astype(np.float32)\n",
        "        mask = np.transpose(mask, (2,0,1)).astype(np.float32)\n",
        "        \n",
        "        # 이미지 Normalization 0~255 픽셀값 --> 0~1 픽셀값\n",
        "        image = torch.Tensor(image) / 255.0\n",
        "        mask = torch.round(torch.Tensor(mask)/255.0)\n",
        "        \n",
        "        return image, mask"
      ],
      "id": "70b2ad0e-6461-4a55-9557-6d0c5e49678c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f87467f8-d244-43e7-8499-1594335f2f41"
      },
      "source": [
        "## 모델 정의"
      ],
      "id": "f87467f8-d244-43e7-8499-1594335f2f41"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "8eafd47a-c32f-4d79-aff6-506a81f5a083"
      },
      "outputs": [],
      "source": [
        "class SegModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SegModel, self).__init__()\n",
        "        \n",
        "        # Pre-train된 UNET 불러오기\n",
        "        self.backbone = smp.DeepLabV3Plus(\n",
        "            encoder_name = ENCODER, # 인코더 모델 설정\n",
        "            encoder_weights = WEIGHTS, # 사전학습 데이터셋 설정\n",
        "            in_channels = 3, # 이미지 디멘션 (3 * 512 * 512)\n",
        "            classes = 1, # 세그멘테이션 클래스 개수 \n",
        "            activation = None # logit 값 불러오기\n",
        "        )\n",
        "        \n",
        "    def forward(self, images):\n",
        "        logits = self.backbone(images)\n",
        "        \n",
        "        return logits"
      ],
      "id": "8eafd47a-c32f-4d79-aff6-506a81f5a083"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f86cf03-108d-4541-9180-813af657008d"
      },
      "source": [
        "## Utils 정의\n",
        "#### Augmentation 함수"
      ],
      "id": "3f86cf03-108d-4541-9180-813af657008d"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "d2686af4-c4a7-4fde-bb54-1a0ce3f49e72"
      },
      "outputs": [],
      "source": [
        "# 나중에 추가 예정\n",
        "def get_train_augs():\n",
        "    return A.Compose([\n",
        "        A.Resize(IMG_SIZE, IMG_SIZE), # 이미지 크기 변환\n",
        "        A.HorizontalFlip(p=0.5), # 이미지 좌우반전\n",
        "        A.VerticalFlip(p=0.5) # 이미지 상하반전\n",
        "    ])\n",
        "\n",
        "def get_valid_augs():\n",
        "    return A.Compose([\n",
        "        A.Resize(IMG_SIZE, IMG_SIZE)\n",
        "    ])"
      ],
      "id": "d2686af4-c4a7-4fde-bb54-1a0ce3f49e72"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "540c43c3-e380-4325-bb10-2cd8c62e56d7"
      },
      "source": [
        "#### Train 함수"
      ],
      "id": "540c43c3-e380-4325-bb10-2cd8c62e56d7"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "e7d69233-2cc3-48c8-a5aa-b17953f6a53b"
      },
      "outputs": [],
      "source": [
        "def train_fn(dataloader, model, optimizer, loss_fn):\n",
        "    model.train()\n",
        "    \n",
        "    total_loss = 0.0\n",
        "    \n",
        "    for images,masks in tqdm(dataloader):\n",
        "        images = images.to(DEVICE)\n",
        "        masks = masks.to(DEVICE)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        logits = model(images)\n",
        "        loss = loss_fn(logits, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        \n",
        "    return total_loss/len(dataloader)"
      ],
      "id": "e7d69233-2cc3-48c8-a5aa-b17953f6a53b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09cbd0cb-f134-47ea-b68e-eef2b2e92ab4"
      },
      "source": [
        "#### Validation 함수"
      ],
      "id": "09cbd0cb-f134-47ea-b68e-eef2b2e92ab4"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "46c21e3f-9170-47ea-bf81-a71b01e89efd"
      },
      "outputs": [],
      "source": [
        "def valid_fn(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    \n",
        "    total_loss = 0.0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images,masks in tqdm(dataloader):\n",
        "            images = images.to(DEVICE)\n",
        "            masks = masks.to(DEVICE)\n",
        "            logits = model(images)\n",
        "            loss = loss_fn(logits, masks)\n",
        "            total_loss += loss.item()\n",
        "    return total_loss/len(dataloader)"
      ],
      "id": "46c21e3f-9170-47ea-bf81-a71b01e89efd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c71db9f2-fdd0-4b0b-8888-fbcaaa607a58"
      },
      "source": [
        "## 모델 학습\n",
        "#### Dataset & Dataloader 설정"
      ],
      "id": "c71db9f2-fdd0-4b0b-8888-fbcaaa607a58"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7ffdac70-018e-4280-bc23-d39eb16d64e2"
      },
      "outputs": [],
      "source": [
        "# 학습 이미지, 마스크 이름 들어있는 CSV 불러와 데이터 프레임으로 저장\n",
        "entiredf = pd.read_csv(TRAIN_CSV_FILE)\n",
        "\n",
        "# Train과 Validation 데이터셋으로 나누기\n",
        "traindf, validdf = train_test_split(entiredf, test_size=0.2)\n",
        "traindf = traindf.reset_index(drop=True)\n",
        "validdf = validdf.reset_index(drop=True)\n",
        "\n",
        "# Dataset 및 Dataloader 설정\n",
        "train_dataset = SegDataset(traindf, get_train_augs(), TRAIN_IMG_DIR, TRAIN_MASK_DIR)\n",
        "valid_dataset = SegDataset(validdf, get_valid_augs(), TRAIN_IMG_DIR, TRAIN_MASK_DIR)\n",
        "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size = BATCH_SIZE)"
      ],
      "id": "7ffdac70-018e-4280-bc23-d39eb16d64e2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6eb184c-a4be-4891-beab-2916870b26f0"
      },
      "source": [
        "#### 모델과 기타 utils 설정"
      ],
      "id": "f6eb184c-a4be-4891-beab-2916870b26f0"
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Dp9uzg8v5ePd"
      },
      "id": "Dp9uzg8v5ePd",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "d0a25c94-b1d3-4ff6-8483-2ab9d26de630"
      },
      "outputs": [],
      "source": [
        "model = SegModel().to(DEVICE) # 모델 설정\n",
        "loss_fn = DiceLoss(mode = 'binary') # 학습 loss funciton 설정\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE) # optimizer 설정"
      ],
      "id": "d0a25c94-b1d3-4ff6-8483-2ab9d26de630"
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "8aKkZxCp6Ol5"
      },
      "id": "8aKkZxCp6Ol5",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5f32e61-19d6-4165-9e09-3c5bdd7b6690"
      },
      "source": [
        "#### Epoch 단위 학습 진행"
      ],
      "id": "a5f32e61-19d6-4165-9e09-3c5bdd7b6690"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "17e06473-8ac6-4066-ad8e-505371e08dfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 998
        },
        "outputId": "949d4c8b-21d3-44ec-e7fd-0e1d335f9d82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 786/786 [1:10:18<00:00,  5.37s/it]\n",
            "100%|██████████| 197/197 [17:09<00:00,  5.22s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved model\n",
            "Epoch: 1, Train Loss: 0.3287247710555564 Valid Loss: 0.2382947732954461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 786/786 [22:47<00:00,  1.74s/it]\n",
            "100%|██████████| 197/197 [04:18<00:00,  1.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved model\n",
            "Epoch: 2, Train Loss: 0.23294260256163035 Valid Loss: 0.2119882630212658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 786/786 [22:39<00:00,  1.73s/it]\n",
            "100%|██████████| 197/197 [04:19<00:00,  1.32s/it]\n",
            "100%|██████████| 786/786 [22:27<00:00,  1.71s/it]\n",
            "100%|██████████| 197/197 [04:16<00:00,  1.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved model\n",
            "Epoch: 4, Train Loss: 0.2025764592124609 Valid Loss: 0.17808521338525762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 786/786 [22:30<00:00,  1.72s/it]\n",
            "100%|██████████| 197/197 [04:17<00:00,  1.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved model\n",
            "Epoch: 5, Train Loss: 0.19383875066390777 Valid Loss: 0.17538662216990128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 786/786 [22:26<00:00,  1.71s/it]\n",
            "100%|██████████| 197/197 [04:15<00:00,  1.30s/it]\n",
            "100%|██████████| 786/786 [22:21<00:00,  1.71s/it]\n",
            "100%|██████████| 197/197 [04:17<00:00,  1.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved model\n",
            "Epoch: 7, Train Loss: 0.17566520620241724 Valid Loss: 0.16008142831966962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 786/786 [22:18<00:00,  1.70s/it]\n",
            "100%|██████████| 197/197 [04:12<00:00,  1.28s/it]\n",
            "100%|██████████| 786/786 [22:08<00:00,  1.69s/it]\n",
            "100%|██████████| 197/197 [04:13<00:00,  1.29s/it]\n",
            "100%|██████████| 786/786 [22:15<00:00,  1.70s/it]\n",
            "100%|██████████| 197/197 [04:14<00:00,  1.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved model\n",
            "Epoch: 10, Train Loss: 0.17102615440468144 Valid Loss: 0.15606370038792566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▎         | 28/786 [00:48<21:57,  1.74s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-8558f2b8aeae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-005cc748b429>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(dataloader, model, optimizer, loss_fn)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    155\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             adam(params_with_grad,\n\u001b[0m\u001b[1;32m    158\u001b[0m                  \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                  \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    214\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "best_loss = np.Inf\n",
        "\n",
        "for i in range(EPOCHS):\n",
        "    train_loss = train_fn(train_loader, model, optimizer, loss_fn)\n",
        "    valid_loss = valid_fn(valid_loader, model, loss_fn)\n",
        "    \n",
        "    # loss가 감소하면 모델 저장\n",
        "    if valid_loss < best_loss:\n",
        "        torch.save(model.state_dict(), os.path.join(RECORDER_DIR, \"best-model.pt\"))\n",
        "        print('saved model')\n",
        "        best_loss = valid_loss\n",
        "        print(f\"Epoch: {i+1}, Train Loss: {train_loss} Valid Loss: {valid_loss}\")"
      ],
      "id": "17e06473-8ac6-4066-ad8e-505371e08dfa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45079578-24cd-4022-bea3-094e1f7ddc6f"
      },
      "source": [
        "## 추론"
      ],
      "id": "45079578-24cd-4022-bea3-094e1f7ddc6f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "858d5a4b-1132-4a3c-b5d8-5ba6d0790d6a"
      },
      "source": [
        "#### 마스크를 RLE 형태로 변환해주는 함수"
      ],
      "id": "858d5a4b-1132-4a3c-b5d8-5ba6d0790d6a"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "e89b6edd-3b4a-47e9-ac7d-46dbc9554d47"
      },
      "outputs": [],
      "source": [
        "def mask_to_rle(mask):\n",
        "    flatten_mask = mask.flatten()\n",
        "    if flatten_mask.max() == 0:\n",
        "        return f'0 {len(flatten_mask)}'\n",
        "    idx = np.where(flatten_mask!=0)[0]\n",
        "    steps = idx[1:]-idx[:-1]\n",
        "    new_coord = []\n",
        "    step_idx = np.where(np.array(steps)!=1)[0]\n",
        "    start = np.append(idx[0], idx[step_idx+1])\n",
        "    end = np.append(idx[step_idx], idx[-1])\n",
        "    length = end - start + 1\n",
        "    for i in range(len(start)):\n",
        "        new_coord.append(start[i])\n",
        "        new_coord.append(length[i])\n",
        "    new_coord_str = ' '.join(map(str, new_coord))\n",
        "    return new_coord_str"
      ],
      "id": "e89b6edd-3b4a-47e9-ac7d-46dbc9554d47"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29918677-0b4d-4d88-95ab-28b459961b7c"
      },
      "source": [
        "#### Test 데이터셋 불러오기"
      ],
      "id": "29918677-0b4d-4d88-95ab-28b459961b7c"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "2d381dfa-582a-440a-855a-a7ba5896f71c"
      },
      "outputs": [],
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, df, img_dir):\n",
        "        self.df = df\n",
        "        self.img_dir = img_dir\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        imname = row['img']\n",
        "        image_path = os.path.join(self.img_dir,imname)\n",
        "        \n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = np.transpose(image, (2,0,1)).astype(np.float32)\n",
        "        image = torch.Tensor(image) / 255.0\n",
        "        \n",
        "        return image,imname"
      ],
      "id": "2d381dfa-582a-440a-855a-a7ba5896f71c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c238286a-a762-4f01-b6d4-1c4b30d6d297"
      },
      "source": [
        "#### 경로 및 기타 인자 설정"
      ],
      "id": "c238286a-a762-4f01-b6d4-1c4b30d6d297"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "fd2f468c-3066-4bdd-8cd8-6db5a1807246"
      },
      "outputs": [],
      "source": [
        "TEST_DIR = os.path.join(DATA_DIR, 'test') # 테스트 데이터가 들어있는 폴더 경로\n",
        "TEST_IMG_DIR = os.path.join(TEST_DIR, 'images') # 테스트 이미지가 들어있는 폴더 경로\n",
        "TEST_CSV_FILE = os.path.join(TEST_DIR, 'testdf.csv') # 테스트 이미지 이름이 들어있는 CSV 경로"
      ],
      "id": "fd2f468c-3066-4bdd-8cd8-6db5a1807246"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a6f1005-184b-43b8-b530-e87c58a3cf6b"
      },
      "source": [
        "#### 테스트 Dataset, DataLoader 설정"
      ],
      "id": "4a6f1005-184b-43b8-b530-e87c58a3cf6b"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "67e19096-8245-4d01-bab6-a9270cfcbc72"
      },
      "outputs": [],
      "source": [
        "testdf = pd.read_csv(TEST_CSV_FILE)\n",
        "test_dataset = TestDataset(testdf, TEST_IMG_DIR)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=1,shuffle=False)"
      ],
      "id": "67e19096-8245-4d01-bab6-a9270cfcbc72"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce62d43b-7c55-4036-b36d-55e1f2a835c4"
      },
      "source": [
        "#### 최고 성능 모델 불러오기"
      ],
      "id": "ce62d43b-7c55-4036-b36d-55e1f2a835c4"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "c016fb2d-2f96-4a36-9832-76f51e64cc18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf4edfc0-f4d8-43d8-f127-2ba59b5c292c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(os.path.join(RECORDER_DIR, 'best-model.pt')))"
      ],
      "id": "c016fb2d-2f96-4a36-9832-76f51e64cc18"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc8ec446-d0ce-4568-99e9-40c9b08486a9"
      },
      "source": [
        "#### 추론 진행"
      ],
      "id": "cc8ec446-d0ce-4568-99e9-40c9b08486a9"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "e3070872-23ec-4489-83b3-27e139173639",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d07c61f-37c4-415a-d2be-23460bfe6a4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1303it [18:57,  1.15it/s]\n"
          ]
        }
      ],
      "source": [
        "file_list = [] # 이미지 이름 저장할 리스트\n",
        "pred_list = [] # 마스크 저장할 리스트\n",
        "class_list = [] # 클래스 이름 저장할 리스트 ('building')\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch_index, (image,imname) in tqdm(enumerate(test_loader)):\n",
        "        image = image.to(DEVICE)\n",
        "        logit_mask = model(image)\n",
        "        pred_mask = torch.sigmoid(logit_mask) # logit 값을 probability score로 변경\n",
        "        pred_mask = (pred_mask > 0.5) * 1.0 # 0.5 이상 확률 가진 픽셀값 1로 변환\n",
        "        pred_rle = mask_to_rle(pred_mask.detach().cpu().squeeze(0)) # 마스크를 RLE 형태로 변경\n",
        "        pred_list.append(pred_rle)\n",
        "        file_list.append(imname[0])\n",
        "        class_list.append(\"building\")\n",
        "        "
      ],
      "id": "e3070872-23ec-4489-83b3-27e139173639"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d00d3a0e-2954-4bc6-94b6-74379222ac45"
      },
      "source": [
        "#### 예측 결과 파일 만들기"
      ],
      "id": "d00d3a0e-2954-4bc6-94b6-74379222ac45"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "0d3687d6-1280-4ea9-b386-c3a2b668c558"
      },
      "outputs": [],
      "source": [
        "# 예측 결과 데이터프레임 만들기\n",
        "results = pd.DataFrame({'img_id':file_list,'class':class_list,'prediction':pred_list})\n",
        "\n",
        "# sample_submission.csv와 같은 형태로 변형\n",
        "sampledf = pd.read_csv(os.path.join(TEST_DIR, 'sample_submission.csv'))\n",
        "sorter = list(sampledf['img_id'])\n",
        "results = results.set_index('img_id')\n",
        "results = results.loc[sorter].reset_index()\n",
        "                       \n",
        "# 결과 저장\n",
        "results.to_csv(os.path.join(RECORDER_DIR, 'prediction3.csv'), index=False)"
      ],
      "id": "0d3687d6-1280-4ea9-b386-c3a2b668c558"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F-hUYTAr2Y6n"
      },
      "id": "F-hUYTAr2Y6n",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}